"use strict";Object.defineProperty(exports,"__esModule",{value:!0});var MetricReduction,ndarray_1=require("../math/ndarray"),session_1=require("./session"),DEFAULT_EVAL_INTERVAL_MS=1500,DEFAULT_COST_INTERVAL_MS=500,DEFAULT_INFERENCE_EXAMPLE_INTERVAL_MS=3e3;!function(e){e[e.SUM=0]="SUM",e[e.MEAN=1]="MEAN"}(MetricReduction=exports.MetricReduction||(exports.MetricReduction={}));var GraphRunner=function(){function e(e,t,r){this.math=e,this.session=t,this.eventObserver=r,this.lastCostTimestamp=0,this.lastEvalTimestamp=0,this.resetStatistics(),this.zeroScalar=ndarray_1.Scalar.new(0)}return e.prototype.resetStatistics=function(){this.totalBatchesTrained=0},e.prototype.train=function(e,t,r,n,i,s,a,o,c,l,h){void 0===c&&(c=MetricReduction.MEAN),void 0===l&&(l=DEFAULT_EVAL_INTERVAL_MS),void 0===h&&(h=DEFAULT_COST_INTERVAL_MS),this.costTensor=e,this.trainFeedEntries=t,this.metricTensor=s,this.metricFeedEntries=a,null!=o&&this.metricBatchSize!==o&&(null!=this.metricBatchSizeScalar&&this.metricBatchSizeScalar.dispose(),this.metricBatchSizeScalar=ndarray_1.Scalar.new(o)),this.metricBatchSize=o,this.metricReduction=c,this.batchSize=r,this.optimizer=n,this.metricIntervalMs=l,this.costIntervalMs=h,this.currentTrainLoopNumBatches=i,this.batchesTrainedThisRun=0,this.isTraining=!0,this.trainStartTimestamp=performance.now(),this.trainNetwork()},e.prototype.stopTraining=function(){this.isTraining=!1},e.prototype.resumeTraining=function(){this.isTraining=!0,this.trainNetwork()},e.prototype.trainNetwork=function(){var i,s,a,o=this;this.batchesTrainedThisRun===this.currentTrainLoopNumBatches&&this.stopTraining(),this.isTraining?(i=performance.now(),(s=null!=this.eventObserver.avgCostCallback&&i-this.lastCostTimestamp>this.costIntervalMs)&&(this.lastCostTimestamp=i),a=s?session_1.CostReduction.MEAN:session_1.CostReduction.NONE,this.math.scope(function(e){var t,r,n=o.session.train(o.costTensor,o.trainFeedEntries,o.batchSize,o.optimizer,a);s&&(t=performance.now()-i,o.eventObserver.avgCostCallback(n),null!=o.eventObserver.trainExamplesPerSecCallback&&(r=1e3*o.batchSize/t,o.eventObserver.trainExamplesPerSecCallback(r))),null!=o.eventObserver.metricCallback&&null!=o.metricFeedEntries&&i-o.lastEvalTimestamp>o.metricIntervalMs&&(o.lastEvalTimestamp=i,null!=o.lastComputedMetric&&o.lastComputedMetric.dispose(),o.lastComputedMetric=o.computeMetric(),o.eventObserver.metricCallback(o.lastComputedMetric)),null!=o.eventObserver.totalTimeCallback&&o.eventObserver.totalTimeCallback((i-o.trainStartTimestamp)/1e3),o.batchesTrainedThisRun++,o.totalBatchesTrained++,null!=o.eventObserver.batchesTrainedCallback&&o.eventObserver.batchesTrainedCallback(o.totalBatchesTrained)}),requestAnimationFrame(function(){return o.trainNetwork()})):null!=this.eventObserver.doneTrainingCallback&&this.eventObserver.doneTrainingCallback()},e.prototype.infer=function(e,t,r,n,i){var s=this;if(void 0===r&&(r=DEFAULT_INFERENCE_EXAMPLE_INTERVAL_MS),void 0===n&&(n=5),null==this.eventObserver.inferenceExamplesCallback&&null==this.eventObserver.inferenceExamplesPerSecCallback)throw new Error("Cannot start inference loop, no inference example or examples/sec observer provided.");for(var a=0;a<t.length;a++){if(t[a].data instanceof ndarray_1.NDArray)throw new Error("Cannot start inference on the model runner with feed entries of type NDArray. Please use InputProviders.")}this.inferenceExampleIntervalMs=r,this.inferenceTensor=e,this.inferenceFeedEntries=t,this.inferenceExampleCount=n,this.currentInferenceLoopNumPasses=i,this.isInferring||(this.inferencePassesThisRun=0,requestAnimationFrame(function(){return s.inferNetwork()})),this.isInferring=!0},e.prototype.inferNetwork=function(){var u=this;this.isInferring&&this.inferencePassesThisRun!==this.currentInferenceLoopNumPasses&&(this.math.scope(function(e){for(var t,r,n=[],i=[],s=performance.now(),a=0;a<u.inferenceExampleCount;a++){for(var o=[],c=0;c<u.inferenceFeedEntries.length;c++){var l=u.inferenceFeedEntries[c],h=l.data.getNextCopy(u.math);o.push({tensor:l.tensor,data:h})}n.push(o),i.push(u.session.eval(u.inferenceTensor,o))}null!=u.eventObserver.inferenceExamplesPerSecCallback&&(i[i.length-1].dataSync(),t=performance.now()-s,r=1e3*u.inferenceExampleCount/t,u.eventObserver.inferenceExamplesPerSecCallback(r)),null!=u.eventObserver.inferenceExamplesCallback&&u.eventObserver.inferenceExamplesCallback(n,i),u.inferencePassesThisRun++}),this.lastInferTimeoutID=window.setTimeout(function(){return u.inferNetwork()},this.inferenceExampleIntervalMs))},e.prototype.stopInferring=function(){this.isInferring=!1,window.clearTimeout(this.lastInferTimeoutID)},e.prototype.isInferenceRunning=function(){return this.isInferring},e.prototype.computeMetric=function(){var n=this;if(null==this.metricFeedEntries)throw new Error("Cannot compute metric, no metric FeedEntries provided.");var i=this.zeroScalar;return this.math.scope(function(e){for(var t=0;t<n.metricBatchSize;t++){var r=n.session.eval(n.metricTensor,n.metricFeedEntries);i=n.math.add(i,r.asType("float32"))}return n.metricReduction===MetricReduction.MEAN&&(i=n.math.divide(i,n.metricBatchSizeScalar)),i})},e.prototype.getTotalBatchesTrained=function(){return this.totalBatchesTrained},e.prototype.getLastComputedMetric=function(){return this.lastComputedMetric},e.prototype.setMath=function(e){this.math=e},e.prototype.setSession=function(e){this.session=e},e.prototype.setInferenceTensor=function(e){this.inferenceTensor=e},e.prototype.setInferenceExampleCount=function(e){this.inferenceExampleCount=e},e}();exports.GraphRunner=GraphRunner;